{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T03:13:27.840167Z",
     "start_time": "2020-08-04T03:13:24.961505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fastprogress\n",
      "  Downloading fastprogress-0.2.4-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: fastprogress\n",
      "Successfully installed fastprogress-0.2.4\n"
     ]
    }
   ],
   "source": [
    "# ! pip install fastprogress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:42:48.213807Z",
     "start_time": "2020-08-06T10:42:45.124919Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import yaml\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "import cv2\n",
    "import librosa\n",
    "import librosa.core\n",
    "import audioread\n",
    "import soundfile as sf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv2d, Module, Linear, BatchNorm2d, ReLU\n",
    "from torch.nn.modules.utils import _pair\n",
    "import torch.utils.data as data\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:42:49.081111Z",
     "start_time": "2020-08-06T10:42:49.071230Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "#     torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "#     torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "    \n",
    "\n",
    "@contextmanager\n",
    "def timer(name: str) -> None:\n",
    "    \"\"\"Timer Util\"\"\"\n",
    "    t0 = time.time()\n",
    "    print(\"[{}] start\".format(name))\n",
    "    yield\n",
    "    print(\"[{}] done in {:.0f} s\".format(name, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:42:50.130823Z",
     "start_time": "2020-08-06T10:42:50.126115Z"
    }
   },
   "outputs": [],
   "source": [
    "set_seed(1213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:42:53.263820Z",
     "start_time": "2020-08-06T10:42:53.242638Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = Path('../../../')\n",
    "# ROOT = Path.cwd().parent  # on kernel\n",
    "INPUT_ROOT = ROOT / \"input\"\n",
    "RAW_DATA = INPUT_ROOT / \"birdsong-recognition\"\n",
    "TRAIN_AUDIO_DIR = RAW_DATA / \"train_audio\"\n",
    "TEST_AUDIO_DIR = RAW_DATA / \"test_audio\"\n",
    "\n",
    "if not TEST_AUDIO_DIR.exists():\n",
    "    TEST_AUDIO_DIR = INPUT_ROOT / \"birdcall-check\" / \"test_audio\"\n",
    "    test = pd.read_csv(INPUT_ROOT / \"birdcall-check\" / \"test.csv\")\n",
    "else:\n",
    "    test = pd.read_csv(RAW_DATA / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:43:07.676695Z",
     "start_time": "2020-08-06T10:43:07.650800Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../../../input/birdsong-recognition/sample_submission.csv\")\n",
    "sub.to_csv(\"../output/test_baseline_1epoch/submission.csv\", index=False)  # this will be overwritten if everything goes well\n",
    "\n",
    "# on kernel\n",
    "# sub = pd.read_csv(\"../input/birdsong-recognition/sample_submission.csv\")\n",
    "# sub.to_csv(\"submission.csv\", index=False)  # this will be overwritten if everything goes well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:43:16.806675Z",
     "start_time": "2020-08-06T10:43:16.799823Z"
    }
   },
   "outputs": [],
   "source": [
    "TARGET_SR = 32000\n",
    "model_config = {\n",
    "    \"base_model_name\": \"resnest50_fast_1s1x64d\",\n",
    "    \"pretrained\": False,\n",
    "    \"num_classes\": 264,\n",
    "    \"trained_weights\": \"../output/test_baseline_1epoch/best_model.pth\"  # ベストモデルのパス指定\n",
    "}\n",
    "\n",
    "melspectrogram_parameters = {\n",
    "    \"n_fft\": 2048\n",
    "    \"n_mels\": 128,\n",
    "    \"fmin\": 200,\n",
    "    \"fmax\": 16000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:43:17.777496Z",
     "start_time": "2020-08-06T10:43:17.736177Z"
    }
   },
   "outputs": [],
   "source": [
    "BIRD_CODE = {\n",
    "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
    "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
    "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
    "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
    "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
    "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
    "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
    "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
    "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
    "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
    "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n",
    "    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n",
    "    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n",
    "    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n",
    "    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n",
    "    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n",
    "    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n",
    "    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n",
    "    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n",
    "    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n",
    "    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n",
    "    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n",
    "    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n",
    "    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n",
    "    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n",
    "    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n",
    "    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n",
    "    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n",
    "    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n",
    "    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n",
    "    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n",
    "    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n",
    "    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n",
    "    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n",
    "    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n",
    "    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n",
    "    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n",
    "    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n",
    "    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n",
    "    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n",
    "    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n",
    "    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n",
    "    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n",
    "    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n",
    "    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n",
    "    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n",
    "    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n",
    "    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n",
    "    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n",
    "    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n",
    "    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n",
    "    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n",
    "    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n",
    "}\n",
    "\n",
    "INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:43:19.618466Z",
     "start_time": "2020-08-06T10:43:19.456840Z"
    }
   },
   "outputs": [],
   "source": [
    "def mono_to_color(X: np.ndarray,\n",
    "                  mean=None,\n",
    "                  std=None,\n",
    "                  norm_max=None,\n",
    "                  norm_min=None,\n",
    "                  eps=1e-6):\n",
    "    \"\"\"\n",
    "    Code from https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data\n",
    "    \"\"\"\n",
    "    # Stack X as [X,X,X]\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V\n",
    "\n",
    "\n",
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, clip: np.ndarray,\n",
    "                 img_size=224, melspectrogram_parameters={}):\n",
    "        self.df = df\n",
    "        self.clip = clip  # 波形の配列\n",
    "        self.img_size = img_size\n",
    "        self.melspectrogram_parameters = melspectrogram_parameters\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def mel(sr, n_fft, n_mels=128, fmin=0.0, fmax=None, htk=False,\n",
    "            norm=1):\n",
    "        \"\"\"Create a Filterbank matrix to combine FFT bins into Mel-frequency bins\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sr        : number > 0 [scalar]\n",
    "            sampling rate of the incoming signal\n",
    "\n",
    "        n_fft     : int > 0 [scalar]\n",
    "            number of FFT components\n",
    "\n",
    "        n_mels    : int > 0 [scalar]\n",
    "            number of Mel bands to generate\n",
    "\n",
    "        fmin      : float >= 0 [scalar]\n",
    "            lowest frequency (in Hz)\n",
    "\n",
    "        fmax      : float >= 0 [scalar]\n",
    "            highest frequency (in Hz).\n",
    "            If `None`, use `fmax = sr / 2.0`\n",
    "\n",
    "        htk       : bool [scalar]\n",
    "            use HTK formula instead of Slaney\n",
    "\n",
    "        norm : {None, 1, np.inf} [scalar]\n",
    "            if 1, divide the triangular mel weights by the width of the mel band\n",
    "            (area normalization).  Otherwise, leave all the triangles aiming for\n",
    "            a peak value of 1.0\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        M         : np.ndarray [shape=(n_mels, 1 + n_fft/2)]\n",
    "            Mel transform matrix\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        This function caches at level 10.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> melfb = librosa.filters.mel(22050, 2048)\n",
    "        >>> melfb\n",
    "        array([[ 0.   ,  0.016, ...,  0.   ,  0.   ],\n",
    "            [ 0.   ,  0.   , ...,  0.   ,  0.   ],\n",
    "            ...,\n",
    "            [ 0.   ,  0.   , ...,  0.   ,  0.   ],\n",
    "            [ 0.   ,  0.   , ...,  0.   ,  0.   ]])\n",
    "\n",
    "\n",
    "        Clip the maximum frequency to 8KHz\n",
    "\n",
    "        >>> librosa.filters.mel(22050, 2048, fmax=8000)\n",
    "        array([[ 0.  ,  0.02, ...,  0.  ,  0.  ],\n",
    "            [ 0.  ,  0.  , ...,  0.  ,  0.  ],\n",
    "            ...,\n",
    "            [ 0.  ,  0.  , ...,  0.  ,  0.  ],\n",
    "            [ 0.  ,  0.  , ...,  0.  ,  0.  ]])\n",
    "\n",
    "\n",
    "        >>> import matplotlib.pyplot as plt\n",
    "        >>> plt.figure()\n",
    "        >>> librosa.display.specshow(melfb, x_axis='linear')\n",
    "        >>> plt.ylabel('Mel filter')\n",
    "        >>> plt.title('Mel filter bank')\n",
    "        >>> plt.colorbar()\n",
    "        >>> plt.tight_layout()\n",
    "        \"\"\"\n",
    "\n",
    "        if fmax is None:\n",
    "            fmax = float(sr) / 2\n",
    "\n",
    "        if norm is not None and norm != 1 and norm != np.inf:\n",
    "            raise ParameterError('Unsupported norm: {}'.format(repr(norm)))\n",
    "\n",
    "        # Initialize the weights\n",
    "        n_mels = int(n_mels)\n",
    "        weights = np.zeros((n_mels, int(1 + n_fft // 2)))\n",
    "\n",
    "        # Center freqs of each FFT bin\n",
    "        fftfreqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "\n",
    "        # 'Center freqs' of mel bands - uniformly spaced between limits\n",
    "        mel_f = np.array([200,\n",
    "                200.65839880255413,\n",
    "                201.37750848432012,\n",
    "                201.51126380583162,\n",
    "                201.67386956899037,\n",
    "                201.87582543688856,\n",
    "                202.13345527203808,\n",
    "                202.47362290912503,\n",
    "                202.94395795945513,\n",
    "                203.63802229847101,\n",
    "                204.7696777583669,\n",
    "                206.9686321525935,\n",
    "                212.88885671471746,\n",
    "                217.43048869703566,\n",
    "                217.67573891228102,\n",
    "                217.99718059148606,\n",
    "                218.43718046012455,\n",
    "                219.07709875345563,\n",
    "                220.09657180388132,\n",
    "                221.99293137020203,\n",
    "                226.94388589196586,\n",
    "                232.62734674169212,\n",
    "                235.10231672457329,\n",
    "                236.44419592188694,\n",
    "                239.27104445621455,\n",
    "                247.84189145158842,\n",
    "                258.1332636574189,\n",
    "                266.45592538764413,\n",
    "                287.9890352180489,\n",
    "                310.53399991020956,\n",
    "                329.7280481648527,\n",
    "                365.2636543430171,\n",
    "                412.1971069913186,\n",
    "                474.9992071267056,\n",
    "                543.8012938633804,\n",
    "                613.9981630065175,\n",
    "                684.4309008264818,\n",
    "                746.926859193976,\n",
    "                824.9481206944652,\n",
    "                934.1647408605522,\n",
    "                1059.406578152521,\n",
    "                1191.4714986828917,\n",
    "                1315.3661976656404,\n",
    "                1417.0854269491579,\n",
    "                1511.4688454929535,\n",
    "                1612.80056993873,\n",
    "                1721.6428871330952,\n",
    "                1838.288761545141,\n",
    "                1955.3394189452179,\n",
    "                2064.968083010285,\n",
    "                2166.8084495171515,\n",
    "                2260.0916983488605,\n",
    "                2338.3314875237083,\n",
    "                2401.906399148228,\n",
    "                2463.7128966413247,\n",
    "                2524.8571234176743,\n",
    "                2580.0580920624607,\n",
    "                2628.9702036006215,\n",
    "                2682.628540587129,\n",
    "                2735.574322816629,\n",
    "                2782.2949980039793,\n",
    "                2823.2077006567883,\n",
    "                2863.515614399661,\n",
    "                2908.3053773334987,\n",
    "                2947.9254283746377,\n",
    "                2987.2898160362897,\n",
    "                3026.660057289936,\n",
    "                3066.3058926403455,\n",
    "                3110.9589651232495,\n",
    "                3150.8433299423505,\n",
    "                3190.7647125250114,\n",
    "                3235.4147868690166,\n",
    "                3275.3314141881165,\n",
    "                3315.610520650735,\n",
    "                3360.6813727382987,\n",
    "                3400.707128832307,\n",
    "                3440.631288594453,\n",
    "                3485.2582072693517,\n",
    "                3525.048226029132,\n",
    "                3565.061232929195,\n",
    "                3610.3530117659466,\n",
    "                3656.158234266066,\n",
    "                3702.626404589744,\n",
    "                3749.713173618707,\n",
    "                3797.136734159918,\n",
    "                3844.688148985763,\n",
    "                3892.179804142279,\n",
    "                3939.684061309631,\n",
    "                3992.7908662105892,\n",
    "                4046.0964639926615,\n",
    "                4094.048026768339,\n",
    "                4147.715225077025,\n",
    "                4201.803328840861,\n",
    "                4250.415130590165,\n",
    "                4304.400570488394,\n",
    "                4358.891311144112,\n",
    "                4413.626381238448,\n",
    "                4468.247903671312,\n",
    "                4523.200949785816,\n",
    "                4584.385109100807,\n",
    "                4646.338108408218,\n",
    "                4708.794686519528,\n",
    "                4771.600484347028,\n",
    "                4834.854981582876,\n",
    "                4904.5553996394865,\n",
    "                4974.441512229322,\n",
    "                5045.491312421904,\n",
    "                5130.717507368683,\n",
    "                5223.421347621407,\n",
    "                5317.079138212701,\n",
    "                5418.7071099135665,\n",
    "                5535.597836296701,\n",
    "                5667.909048600521,\n",
    "                5808.1872217746295,\n",
    "                5956.457881201861,\n",
    "                6127.4753815696895,\n",
    "                6314.274205611619,\n",
    "                6509.692128073985,\n",
    "                6736.107119503475,\n",
    "                7008.663641495503,\n",
    "                7312.530456313335,\n",
    "                7655.887319816534,\n",
    "                8100.341736238419,\n",
    "                8973.536714095795,\n",
    "                10144.613928413162,\n",
    "                11315.69114273053,\n",
    "                12486.768357047898,\n",
    "                13657.845571365266,\n",
    "                14828.922785682633,\n",
    "                16000])\n",
    "\n",
    "        fdiff = np.diff(mel_f)\n",
    "        ramps = np.subtract.outer(mel_f, fftfreqs)\n",
    "\n",
    "        for i in range(n_mels):\n",
    "            # lower and upper slopes for all bins\n",
    "            lower = -ramps[i] / fdiff[i]\n",
    "            upper = ramps[i+2] / fdiff[i+1]\n",
    "\n",
    "            # .. then intersect them with each other and zero\n",
    "            weights[i] = np.maximum(0, np.minimum(lower, upper))\n",
    "\n",
    "        if norm == 1:\n",
    "            # Slaney-style mel is scaled to be approx constant energy per channel\n",
    "            enorm = 2.0 / (mel_f[2:n_mels+2] - mel_f[:n_mels])\n",
    "            weights *= enorm[:, np.newaxis]\n",
    "\n",
    "        # Only check weights if f_mel[0] is positive\n",
    "        if not np.all((mel_f[:-2] == 0) | (weights.max(axis=1) > 0)):\n",
    "            # This means we have an empty channel somewhere\n",
    "            warnings.warn('Empty filters detected in mel frequency basis. '\n",
    "                        'Some channels will produce empty responses. '\n",
    "                        'Try increasing your sampling rate (and fmax) or '\n",
    "                        'reducing n_mels.')\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        SR = 32000\n",
    "        sample = self.df.loc[idx, :]\n",
    "        site = sample.site\n",
    "        row_id = sample.row_id\n",
    "        \n",
    "         # site3は長さが様々な音源なので5secondにクリップする必要がある\n",
    "        if site == \"site_3\":\n",
    "            y = self.clip.astype(np.float32)\n",
    "            len_y = len(y)\n",
    "            start = 0\n",
    "            end = SR * 5\n",
    "            images = []\n",
    "            while len_y > start:\n",
    "                y_batch = y[start:end].astype(np.float32)\n",
    "                if len(y_batch) != (SR * 5):\n",
    "                    break\n",
    "                start = end\n",
    "                end = end + SR * 5\n",
    "                \n",
    "                n_fft = self.melspectrogram_parameters[\"n_fft\"]\n",
    "                if self.filterbank: pass\n",
    "                else: \n",
    "                    self.filterbank = self.mel(SR, \n",
    "                        n_fft=n_fft, \n",
    "                        n_mels=self.melspectrogram_parameters[\"n_mels\"], \n",
    "                        fmin=self.melspectrogram_parameters[\"fmin\"],\n",
    "                        fmax=self.melspectrogram_parameters[\"fmax\"])\n",
    "\n",
    "                power = 2.0\n",
    "                S = np.abs(librosa.stft(y, n_fft=n_fft))**power\n",
    "                melspec = np.dot(self.filterbank, S)\n",
    "                \n",
    "                melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "                image = mono_to_color(melspec)\n",
    "                height, width, _ = image.shape\n",
    "                image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "                image = np.moveaxis(image, 2, 0)\n",
    "                image = (image / 255.0).astype(np.float32)\n",
    "                images.append(image)\n",
    "            images = np.asarray(images)\n",
    "            return images, row_id, site\n",
    "        else:\n",
    "            end_seconds = int(sample.seconds)\n",
    "            start_seconds = int(end_seconds - 5)\n",
    "            \n",
    "            start_index = SR * start_seconds\n",
    "            end_index = SR * end_seconds\n",
    "            \n",
    "            y = self.clip[start_index:end_index].astype(np.float32)\n",
    "\n",
    "            n_fft = self.melspectrogram_parameters[\"n_fft\"]\n",
    "            if self.filterbank: pass\n",
    "            else: \n",
    "                self.filterbank = self.mel(SR, \n",
    "                    n_fft=n_fft, \n",
    "                    n_mels=self.melspectrogram_parameters[\"n_mels\"], \n",
    "                    fmin=self.melspectrogram_parameters[\"fmin\"],\n",
    "                    fmax=self.melspectrogram_parameters[\"fmax\"])\n",
    "\n",
    "            power = 2.0\n",
    "            S = np.abs(librosa.stft(y, n_fft=n_fft))**power\n",
    "            melspec = np.dot(self.filterbank, S)\n",
    "            melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "\n",
    "            image = mono_to_color(melspec)\n",
    "            height, width, _ = image.shape\n",
    "            image = cv2.resize(image, (int(width * self.img_size / height), self.img_size))\n",
    "            image = np.moveaxis(image, 2, 0)\n",
    "            image = (image / 255.0).astype(np.float32)\n",
    "\n",
    "            return image, row_id, site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:43:20.594982Z",
     "start_time": "2020-08-06T10:43:20.521589Z"
    }
   },
   "outputs": [],
   "source": [
    "class SplAtConv2d(Module):\n",
    "    \"\"\"Split-Attention Conv2d\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, channels, kernel_size, stride=(1, 1), padding=(0, 0),\n",
    "                 dilation=(1, 1), groups=1, bias=True,\n",
    "                 radix=2, reduction_factor=4,\n",
    "                 rectify=False, rectify_avg=False, norm_layer=None,\n",
    "                 dropblock_prob=0.0, **kwargs):\n",
    "        super(SplAtConv2d, self).__init__()\n",
    "        padding = _pair(padding)\n",
    "        self.rectify = rectify and (padding[0] > 0 or padding[1] > 0)\n",
    "        self.rectify_avg = rectify_avg\n",
    "        inter_channels = max(in_channels*radix//reduction_factor, 32)\n",
    "        self.radix = radix\n",
    "        self.cardinality = groups\n",
    "        self.channels = channels\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        if self.rectify:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv = RFConv2d(in_channels, channels*radix, kernel_size, stride, padding, dilation,\n",
    "                                 groups=groups*radix, bias=bias, average_mode=rectify_avg, **kwargs)\n",
    "        else:\n",
    "            self.conv = Conv2d(in_channels, channels*radix, kernel_size, stride, padding, dilation,\n",
    "                               groups=groups*radix, bias=bias, **kwargs)\n",
    "        self.use_bn = norm_layer is not None\n",
    "        if self.use_bn:\n",
    "            self.bn0 = norm_layer(channels*radix)\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc1 = Conv2d(channels, inter_channels, 1, groups=self.cardinality)\n",
    "        if self.use_bn:\n",
    "            self.bn1 = norm_layer(inter_channels)\n",
    "        self.fc2 = Conv2d(inter_channels, channels*radix, 1, groups=self.cardinality)\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock = DropBlock2D(dropblock_prob, 3)\n",
    "        self.rsoftmax = rSoftMax(radix, groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn0(x)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            x = self.dropblock(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        batch, rchannel = x.shape[:2]\n",
    "        if self.radix > 1:\n",
    "            if torch.__version__ < '1.5':\n",
    "                splited = torch.split(x, int(rchannel//self.radix), dim=1)\n",
    "            else:\n",
    "                splited = torch.split(x, rchannel//self.radix, dim=1)\n",
    "            gap = sum(splited) \n",
    "        else:\n",
    "            gap = x\n",
    "        gap = F.adaptive_avg_pool2d(gap, 1)\n",
    "        gap = self.fc1(gap)\n",
    "\n",
    "        if self.use_bn:\n",
    "            gap = self.bn1(gap)\n",
    "        gap = self.relu(gap)\n",
    "\n",
    "        atten = self.fc2(gap)\n",
    "        atten = self.rsoftmax(atten).view(batch, -1, 1, 1)\n",
    "\n",
    "        if self.radix > 1:\n",
    "            if torch.__version__ < '1.5':\n",
    "                attens = torch.split(atten, int(rchannel//self.radix), dim=1)\n",
    "            else:\n",
    "                attens = torch.split(atten, rchannel//self.radix, dim=1)\n",
    "            out = sum([att*split for (att, split) in zip(attens, splited)])\n",
    "        else:\n",
    "            out = atten * x\n",
    "        return out.contiguous()\n",
    "\n",
    "class rSoftMax(nn.Module):\n",
    "    def __init__(self, radix, cardinality):\n",
    "        super().__init__()\n",
    "        self.radix = radix\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.size(0)\n",
    "        if self.radix > 1:\n",
    "            x = x.view(batch, self.cardinality, self.radix, -1).transpose(1, 2)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            x = x.reshape(batch, -1)\n",
    "        else:\n",
    "            x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class DropBlock2D(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Global average pooling over the input's spatial dimensions\"\"\"\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return nn.functional.adaptive_avg_pool2d(inputs, 1).view(inputs.size(0), -1)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet Bottleneck\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-argument\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 radix=1, cardinality=1, bottleneck_width=64,\n",
    "                 avd=False, avd_first=False, dilation=1, is_first=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 norm_layer=None, dropblock_prob=0.0, last_gamma=False):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        group_width = int(planes * (bottleneck_width / 64.)) * cardinality\n",
    "        self.conv1 = nn.Conv2d(inplanes, group_width, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm_layer(group_width)\n",
    "        self.dropblock_prob = dropblock_prob\n",
    "        self.radix = radix\n",
    "        self.avd = avd and (stride > 1 or is_first)\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        if self.avd:\n",
    "            self.avd_layer = nn.AvgPool2d(3, stride, padding=1)\n",
    "            stride = 1\n",
    "\n",
    "        if dropblock_prob > 0.0:\n",
    "            self.dropblock1 = DropBlock2D(dropblock_prob, 3)\n",
    "            if radix == 1:\n",
    "                self.dropblock2 = DropBlock2D(dropblock_prob, 3)\n",
    "            self.dropblock3 = DropBlock2D(dropblock_prob, 3)\n",
    "\n",
    "        if radix >= 1:\n",
    "            self.conv2 = SplAtConv2d(\n",
    "                group_width, group_width, kernel_size=3,\n",
    "                stride=stride, padding=dilation,\n",
    "                dilation=dilation, groups=cardinality, bias=False,\n",
    "                radix=radix, rectify=rectified_conv,\n",
    "                rectify_avg=rectify_avg,\n",
    "                norm_layer=norm_layer,\n",
    "                dropblock_prob=dropblock_prob)\n",
    "        elif rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            self.conv2 = RFConv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False,\n",
    "                average_mode=rectify_avg)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(\n",
    "                group_width, group_width, kernel_size=3, stride=stride,\n",
    "                padding=dilation, dilation=dilation,\n",
    "                groups=cardinality, bias=False)\n",
    "            self.bn2 = norm_layer(group_width)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            group_width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes*4)\n",
    "\n",
    "        if last_gamma:\n",
    "            from torch.nn.init import zeros_\n",
    "            zeros_(self.bn3.weight)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.avd and self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        if self.radix == 0:\n",
    "            out = self.bn2(out)\n",
    "            if self.dropblock_prob > 0.0:\n",
    "                out = self.dropblock2(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "        if self.avd and not self.avd_first:\n",
    "            out = self.avd_layer(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.dropblock_prob > 0.0:\n",
    "            out = self.dropblock3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"ResNet Variants\n",
    "    Parameters\n",
    "    ----------\n",
    "    block : Block\n",
    "        Class for the residual block. Options are BasicBlockV1, BottleneckV1.\n",
    "    layers : list of int\n",
    "        Numbers of layers in each block\n",
    "    classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    dilated : bool, default False\n",
    "        Applying dilation strategy to pretrained ResNet yielding a stride-8 model,\n",
    "        typically used in Semantic Segmentation.\n",
    "    norm_layer : object\n",
    "        Normalization layer used in backbone network (default: :class:`mxnet.gluon.nn.BatchNorm`;\n",
    "        for Synchronized Cross-GPU BachNormalization).\n",
    "    Reference:\n",
    "        - He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n",
    "        - Yu, Fisher, and Vladlen Koltun. \"Multi-scale context aggregation by dilated convolutions.\"\n",
    "    \"\"\"\n",
    "    # pylint: disable=unused-variable\n",
    "    def __init__(self, block, layers, radix=1, groups=1, bottleneck_width=64,\n",
    "                 num_classes=1000, dilated=False, dilation=1,\n",
    "                 deep_stem=False, stem_width=64, avg_down=False,\n",
    "                 rectified_conv=False, rectify_avg=False,\n",
    "                 avd=False, avd_first=False,\n",
    "                 final_drop=0.0, dropblock_prob=0,\n",
    "                 last_gamma=False, norm_layer=nn.BatchNorm2d):\n",
    "        self.cardinality = groups\n",
    "        self.bottleneck_width = bottleneck_width\n",
    "        # ResNet-D params\n",
    "        self.inplanes = stem_width*2 if deep_stem else 64\n",
    "        self.avg_down = avg_down\n",
    "        self.last_gamma = last_gamma\n",
    "        # ResNeSt params\n",
    "        self.radix = radix\n",
    "        self.avd = avd\n",
    "        self.avd_first = avd_first\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        self.rectified_conv = rectified_conv\n",
    "        self.rectify_avg = rectify_avg\n",
    "        if rectified_conv:\n",
    "            from rfconv import RFConv2d\n",
    "            conv_layer = RFConv2d\n",
    "        else:\n",
    "            conv_layer = nn.Conv2d\n",
    "        conv_kwargs = {'average_mode': rectify_avg} if rectified_conv else {}\n",
    "        if deep_stem:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                conv_layer(3, stem_width, kernel_size=3, stride=2, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "                norm_layer(stem_width),\n",
    "                nn.ReLU(inplace=True),\n",
    "                conv_layer(stem_width, stem_width*2, kernel_size=3, stride=1, padding=1, bias=False, **conv_kwargs),\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = conv_layer(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False, **conv_kwargs)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], norm_layer=norm_layer, is_first=False)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, norm_layer=norm_layer)\n",
    "        if dilated or dilation == 4:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=4, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        elif dilation==2:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           dilation=1, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                           dilation=2, norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        else:\n",
    "            self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "            self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           dropblock_prob=dropblock_prob)\n",
    "        self.avgpool = GlobalAvgPool2d()\n",
    "        self.drop = nn.Dropout(final_drop) if final_drop > 0.0 else None\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, norm_layer):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, norm_layer=None,\n",
    "                    dropblock_prob=0.0, is_first=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            down_layers = []\n",
    "            if self.avg_down:\n",
    "                if dilation == 1:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=stride, stride=stride,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                else:\n",
    "                    down_layers.append(nn.AvgPool2d(kernel_size=1, stride=1,\n",
    "                                                    ceil_mode=True, count_include_pad=False))\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=1, bias=False))\n",
    "            else:\n",
    "                down_layers.append(nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                                             kernel_size=1, stride=stride, bias=False))\n",
    "            down_layers.append(norm_layer(planes * block.expansion))\n",
    "            downsample = nn.Sequential(*down_layers)\n",
    "\n",
    "        layers = []\n",
    "        if dilation == 1 or dilation == 2:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=1, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        elif dilation == 4:\n",
    "            layers.append(block(self.inplanes, planes, stride, downsample=downsample,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=2, is_first=is_first, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "        else:\n",
    "            raise RuntimeError(\"=> unknown dilation size: {}\".format(dilation))\n",
    "\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,\n",
    "                                radix=self.radix, cardinality=self.cardinality,\n",
    "                                bottleneck_width=self.bottleneck_width,\n",
    "                                avd=self.avd, avd_first=self.avd_first,\n",
    "                                dilation=dilation, rectified_conv=self.rectified_conv,\n",
    "                                rectify_avg=self.rectify_avg,\n",
    "                                norm_layer=norm_layer, dropblock_prob=dropblock_prob,\n",
    "                                last_gamma=self.last_gamma))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.drop:\n",
    "            x = self.drop(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:43:21.564112Z",
     "start_time": "2020-08-06T10:43:21.557086Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(args: tp.Dict):\n",
    "    # # get resnest50_fast_1s1x64d\n",
    "    model = ResNet(\n",
    "        Bottleneck, [3, 4, 6, 3],\n",
    "        radix=1, groups=1, bottleneck_width=64,\n",
    "        deep_stem=True, stem_width=32, avg_down=True,\n",
    "        avd=True, avd_first=True)\n",
    "    \n",
    "    del model.fc\n",
    "    # # use the same head as the baseline notebook.\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        nn.Linear(1024, 1024), nn.ReLU(), nn.Dropout(p=0.2),\n",
    "        nn.Linear(1024, args[\"num_classes\"]))\n",
    "    \n",
    "    state_dict = torch.load(args[\"trained_weights\"])\n",
    "    model.load_state_dict(state_dict)\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:43:22.515962Z",
     "start_time": "2020-08-06T10:43:22.498424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>row_id</th>\n",
       "      <th>seconds</th>\n",
       "      <th>audio_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>site_1</td>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41e6fe6504a34bf6846938ba78d13df1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>site_1</td>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41e6fe6504a34bf6846938ba78d13df1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>site_1</td>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>41e6fe6504a34bf6846938ba78d13df1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>site_1</td>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41e6fe6504a34bf6846938ba78d13df1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>site_1</td>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_25</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41e6fe6504a34bf6846938ba78d13df1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     site                                      row_id  seconds  \\\n",
       "0  site_1   site_1_41e6fe6504a34bf6846938ba78d13df1_5      5.0   \n",
       "1  site_1  site_1_41e6fe6504a34bf6846938ba78d13df1_10     10.0   \n",
       "2  site_1  site_1_41e6fe6504a34bf6846938ba78d13df1_15     15.0   \n",
       "3  site_1  site_1_41e6fe6504a34bf6846938ba78d13df1_20     20.0   \n",
       "4  site_1  site_1_41e6fe6504a34bf6846938ba78d13df1_25     25.0   \n",
       "\n",
       "                           audio_id  \n",
       "0  41e6fe6504a34bf6846938ba78d13df1  \n",
       "1  41e6fe6504a34bf6846938ba78d13df1  \n",
       "2  41e6fe6504a34bf6846938ba78d13df1  \n",
       "3  41e6fe6504a34bf6846938ba78d13df1  \n",
       "4  41e6fe6504a34bf6846938ba78d13df1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:43:23.213040Z",
     "start_time": "2020-08-06T10:43:23.192190Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction_for_clip(test_df: pd.DataFrame, \n",
    "                        clip: np.ndarray, \n",
    "                        model: ResNet, \n",
    "                        mel_params: dict, \n",
    "                        threshold=0.5):\n",
    "\n",
    "    dataset = TestDataset(df=test_df, \n",
    "                          clip=clip,\n",
    "                          img_size=224,\n",
    "                          melspectrogram_parameters=mel_params)\n",
    "    loader = data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    prediction_dict = {}\n",
    "    for image, row_id, site in progress_bar(loader):\n",
    "        site = site[0]\n",
    "        row_id = row_id[0]\n",
    "        if site in {\"site_1\", \"site_2\"}:\n",
    "            image = image.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction = F.sigmoid(model(image))\n",
    "                proba = prediction.detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "            events = proba >= threshold\n",
    "            labels = np.argwhere(events).reshape(-1).tolist()\n",
    "\n",
    "        else:\n",
    "            # to avoid prediction on large batch\n",
    "            image = image.squeeze(0)\n",
    "            batch_size = 16\n",
    "            whole_size = image.size(0)\n",
    "            if whole_size % batch_size == 0:\n",
    "                n_iter = whole_size // batch_size\n",
    "            else:\n",
    "                n_iter = whole_size // batch_size + 1\n",
    "                \n",
    "            all_events = set()\n",
    "            for batch_i in range(n_iter):\n",
    "                batch = image[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "                if batch.ndim == 3:\n",
    "                    batch = batch.unsqueeze(0)\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    prediction = F.sigmoid(model(batch))\n",
    "                    proba = prediction.detach().cpu().numpy()\n",
    "                    \n",
    "                events = proba >= threshold\n",
    "                for i in range(len(events)):\n",
    "                    event = events[i, :]\n",
    "                    labels = np.argwhere(event).reshape(-1).tolist()\n",
    "                    for label in labels:\n",
    "                        all_events.add(label)\n",
    "                        \n",
    "            labels = list(all_events)\n",
    "        if len(labels) == 0:\n",
    "            prediction_dict[row_id] = \"nocall\"\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: INV_BIRD_CODE[x], labels))\n",
    "            label_string = \" \".join(labels_str_list)\n",
    "            prediction_dict[row_id] = label_string\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:43:23.779631Z",
     "start_time": "2020-08-06T10:43:23.767914Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(test_df: pd.DataFrame,\n",
    "               test_audio: Path,\n",
    "               model_config: dict,\n",
    "               mel_params: dict,\n",
    "               target_sr: int,\n",
    "               threshold=0.5):\n",
    "    model = get_model(model_config)\n",
    "    unique_audio_id = test_df.audio_id.unique()\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "    for audio_id in unique_audio_id:\n",
    "        with timer(f\"Loading {audio_id}\"):\n",
    "            clip, _ = librosa.load(test_audio / (audio_id + \".mp3\"),\n",
    "                                   sr=target_sr,\n",
    "                                   mono=True,\n",
    "                                   res_type=\"kaiser_fast\")\n",
    "        \n",
    "        test_df_for_audio_id = test_df.query(\n",
    "            f\"audio_id == '{audio_id}'\").reset_index(drop=True)\n",
    "        with timer(f\"Prediction on {audio_id}\"):\n",
    "            prediction_dict = prediction_for_clip(test_df_for_audio_id,\n",
    "                                                  clip=clip,\n",
    "                                                  model=model,\n",
    "                                                  mel_params=mel_params,\n",
    "                                                  threshold=threshold)\n",
    "        row_id = list(prediction_dict.keys())\n",
    "        birds = list(prediction_dict.values())\n",
    "        prediction_df = pd.DataFrame({\n",
    "            \"row_id\": row_id,\n",
    "            \"birds\": birds\n",
    "        })\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T10:43:47.248814Z",
     "start_time": "2020-08-06T10:43:24.602840Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loading 41e6fe6504a34bf6846938ba78d13df1] start\n",
      "[Loading 41e6fe6504a34bf6846938ba78d13df1] done in 1 s\n",
      "[Prediction on 41e6fe6504a34bf6846938ba78d13df1] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 41e6fe6504a34bf6846938ba78d13df1] done in 0 s\n",
      "[Loading cce64fffafed40f2b2f3d3413ec1c4c2] start\n",
      "[Loading cce64fffafed40f2b2f3d3413ec1c4c2] done in 1 s\n",
      "[Prediction on cce64fffafed40f2b2f3d3413ec1c4c2] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7/7 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on cce64fffafed40f2b2f3d3413ec1c4c2] done in 0 s\n",
      "[Loading 99af324c881246949408c0b1ae54271f] start\n",
      "[Loading 99af324c881246949408c0b1ae54271f] done in 1 s\n",
      "[Prediction on 99af324c881246949408c0b1ae54271f] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7/7 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 99af324c881246949408c0b1ae54271f] done in 0 s\n",
      "[Loading 6ab74e177aa149468a39ca10beed6222] start\n",
      "[Loading 6ab74e177aa149468a39ca10beed6222] done in 1 s\n",
      "[Prediction on 6ab74e177aa149468a39ca10beed6222] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6/6 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 6ab74e177aa149468a39ca10beed6222] done in 0 s\n",
      "[Loading b2fd3f01e9284293a1e33f9c811a2ed6] start\n",
      "[Loading b2fd3f01e9284293a1e33f9c811a2ed6] done in 1 s\n",
      "[Prediction on b2fd3f01e9284293a1e33f9c811a2ed6] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7/7 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on b2fd3f01e9284293a1e33f9c811a2ed6] done in 0 s\n",
      "[Loading de62b37ebba749d2abf29d4a493ea5d4] start\n",
      "[Loading de62b37ebba749d2abf29d4a493ea5d4] done in 1 s\n",
      "[Prediction on de62b37ebba749d2abf29d4a493ea5d4] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on de62b37ebba749d2abf29d4a493ea5d4] done in 0 s\n",
      "[Loading 8680a8dd845d40f296246dbed0d37394] start\n",
      "[Loading 8680a8dd845d40f296246dbed0d37394] done in 1 s\n",
      "[Prediction on 8680a8dd845d40f296246dbed0d37394] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [9/9 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 8680a8dd845d40f296246dbed0d37394] done in 0 s\n",
      "[Loading 940d546e5eb745c9a74bce3f35efa1f9] start\n",
      "[Loading 940d546e5eb745c9a74bce3f35efa1f9] done in 1 s\n",
      "[Prediction on 940d546e5eb745c9a74bce3f35efa1f9] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14' class='' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14/14 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 940d546e5eb745c9a74bce3f35efa1f9] done in 1 s\n",
      "[Loading 07ab324c602e4afab65ddbcc746c31b5] start\n",
      "[Loading 07ab324c602e4afab65ddbcc746c31b5] done in 1 s\n",
      "[Prediction on 07ab324c602e4afab65ddbcc746c31b5] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 07ab324c602e4afab65ddbcc746c31b5] done in 0 s\n",
      "[Loading 899616723a32409c996f6f3441646c2a] start\n",
      "[Loading 899616723a32409c996f6f3441646c2a] done in 1 s\n",
      "[Prediction on 899616723a32409c996f6f3441646c2a] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10/10 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 899616723a32409c996f6f3441646c2a] done in 0 s\n",
      "[Loading 9cc5d9646f344f1bbb52640a988fe902] start\n",
      "[Loading 9cc5d9646f344f1bbb52640a988fe902] done in 3 s\n",
      "[Prediction on 9cc5d9646f344f1bbb52640a988fe902] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 9cc5d9646f344f1bbb52640a988fe902] done in 1 s\n",
      "[Loading a56e20a518684688a9952add8a9d5213] start\n",
      "[Loading a56e20a518684688a9952add8a9d5213] done in 1 s\n",
      "[Prediction on a56e20a518684688a9952add8a9d5213] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on a56e20a518684688a9952add8a9d5213] done in 0 s\n",
      "[Loading 96779836288745728306903d54e264dd] start\n",
      "[Loading 96779836288745728306903d54e264dd] done in 1 s\n",
      "[Prediction on 96779836288745728306903d54e264dd] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 96779836288745728306903d54e264dd] done in 0 s\n",
      "[Loading f77783ba4c6641bc918b034a18c23e53] start\n",
      "[Loading f77783ba4c6641bc918b034a18c23e53] done in 1 s\n",
      "[Prediction on f77783ba4c6641bc918b034a18c23e53] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on f77783ba4c6641bc918b034a18c23e53] done in 0 s\n",
      "[Loading 856b194b097441958697c2bcd1f63982] start\n",
      "[Loading 856b194b097441958697c2bcd1f63982] done in 1 s\n",
      "[Prediction on 856b194b097441958697c2bcd1f63982] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 856b194b097441958697c2bcd1f63982] done in 0 s\n"
     ]
    }
   ],
   "source": [
    "submission = prediction(test_df=test,\n",
    "                        test_audio=TEST_AUDIO_DIR,\n",
    "                        model_config=model_config,\n",
    "                        mel_params=melspectrogram_parameters,\n",
    "                        target_sr=TARGET_SR,\n",
    "                        threshold=0.6)\n",
    "submission.to_csv(\"../output/test_baseline_1epoch/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}